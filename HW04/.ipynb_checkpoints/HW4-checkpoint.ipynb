{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ananya Singh\n",
    "# Date: \n",
    "# CS301-006, Professor Watson\n",
    "# HW4 Solution\n",
    "# Brief description of the project: \n",
    "# link to the git repo: \n",
    "# link-to-the-relevant-git-commit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def get_percent_nans(df, column_name):\n",
    "    specific_column = df[column_name]\n",
    "    #grades_df.loc[(grades_df['Midterm'].isna())]\n",
    "    #return len(df.loc[specific_column.isna()])\n",
    "    return (len(df.loc[specific_column.isna()])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"~/Desktop/CS301-DataScience/HW04/2019-coronavirus-dataset-01212020-01262020/2019_nCoV_20200121_20200206.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.31166755460842"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_percent_nans(data_df, \"Suspected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.670218433670755"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_percent_nans(data_df, \"Recovered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Province/State column has 24.45% empty values\n",
      "The Country/Region column has 0.00% empty values\n",
      "The Last Update column has 0.00% empty values\n",
      "The Confirmed column has 1.60% empty values\n",
      "The Suspected column has 95.31% empty values\n",
      "The Recovered column has 46.67% empty values\n",
      "The Death column has 53.22% empty values\n"
     ]
    }
   ],
   "source": [
    "for col in data_df.columns:\n",
    "    print('The {} column has {:.2f}% empty values'.format(col,get_percent_nans(data_df,col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Suspected</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 16:43</td>\n",
       "      <td>16678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 13:23</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:13</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:03</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:23</td>\n",
       "      <td>661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1876</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
       "0             Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
       "1         Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
       "2          Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
       "3             Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
       "4             Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
       "...             ...             ...           ...        ...        ...   \n",
       "1872   Heilongjiang  Mainland China     1/21/2020        NaN        1.0   \n",
       "1873            NaN           Japan     1/21/2020        1.0        NaN   \n",
       "1874            NaN        Thailand     1/21/2020        2.0        NaN   \n",
       "1875            NaN     South Korea     1/21/2020        1.0        NaN   \n",
       "1876     Washington   United States     1/21/2020        1.0        NaN   \n",
       "\n",
       "      Recovered  Death  \n",
       "0         538.0  479.0  \n",
       "1          49.0    0.0  \n",
       "2          78.0    0.0  \n",
       "3          47.0    2.0  \n",
       "4          54.0    0.0  \n",
       "...         ...    ...  \n",
       "1872        NaN    NaN  \n",
       "1873        NaN    NaN  \n",
       "1874        NaN    NaN  \n",
       "1875        NaN    NaN  \n",
       "1876        NaN    NaN  \n",
       "\n",
       "[1877 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Country/Region with the most amount of deaths is Mainland China\n"
     ]
    }
   ],
   "source": [
    "#2 most deaths\n",
    "answer = data_df.groupby(\"Country/Region\")[\"Death\"].sum().idxmax()\n",
    "print(\"The Country/Region with the most amount of deaths is \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Country/Region with the highest number of suspected cases is Hong Kong\n"
     ]
    }
   ],
   "source": [
    "#3 suspected cases\n",
    "answer = data_df.groupby(\"Country/Region\")[\"Suspected\"].sum().idxmax()\n",
    "print(\"The Country/Region with the highest number of suspected cases is \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Country/Region with the second highest avg number of recovered cases is Thailand\n"
     ]
    }
   ],
   "source": [
    "#4 second highest avg(mean) number of recovered cases --> use reset index\n",
    "answer = data_df.groupby(\"Country/Region\")[\"Recovered\"].mean().sort_values(ascending=False).reset_index().iloc[1][\"Country/Region\"]\n",
    "print(\"The Country/Region with the second highest avg number of recovered cases is \" + answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vietnam', 'United Arab Emirates', 'Thailand', 'Taiwan', 'Sri Lanka', 'South Korea', 'Singapore', 'Philippines', 'Nepal', 'Malaysia', 'Mainland China', 'Macau', 'Japan', 'India', 'Hong Kong']\n"
     ]
    }
   ],
   "source": [
    "#5 Create a dictionary which maps the Country/Region to the continent it is part of\n",
    "#cars = ['Ford A', 'BMW A', 'Volvo']\n",
    "cars = ['Hong Kong','India','Japan','Macau','Mainland China','Malaysia','Nepal','Philippines','Singapore','South Korea','Sri Lanka','Taiwan','Thailand','United Arab Emirates','Vietnam']\n",
    "cars.sort(reverse = True)\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping = {\n",
    "    'Asia':['Vietnam', \n",
    "            'United Arab Emirates', \n",
    "            'Thailand', \n",
    "            'Taiwan', \n",
    "            'Sri Lanka', \n",
    "            'South Korea', \n",
    "            'Singapore', \n",
    "            'Philippines', \n",
    "            'Nepal', \n",
    "            'Malaysia', \n",
    "            'Mainland China', \n",
    "            'Macau', \n",
    "            'Japan', \n",
    "            'India', \n",
    "            'Hong Kong'],\n",
    "    'Europe':['UK', \n",
    "              'Sweden', \n",
    "              'Spain', \n",
    "              'Russia', \n",
    "              'Italy', \n",
    "              'Germany', \n",
    "              'France', \n",
    "              'Finland', \n",
    "              'Belgium'],'North America':['Canada','Mexico','United States'],'South America':['Brazil','Colombia'],'Africa':['Cambodia','Ivory Coast'],'Australia':['Australia'],'Antarctica':['']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UK', 'Sweden', 'Spain', 'Russia', 'Italy', 'Germany', 'France', 'Finland', 'Belgium']\n"
     ]
    }
   ],
   "source": [
    "lst = ['Belgium','Finland','France','Germany','Italy','Russia','Spain','Sweden','UK']\n",
    "lst.sort(reverse=True)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
